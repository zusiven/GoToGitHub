import socket
import datetime as dt
import time
import dns.resolver
import ssl
import logging
from pathlib import Path
from typing import List, Tuple, Set, Dict, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

# ==================== é…ç½®åŒº ====================

# å…¨çƒ DNS æœåŠ¡å™¨åˆ—è¡¨
DNS_SERVERS = {
    'Google-US': '8.8.8.8',
    'Google-US-2': '8.8.4.4',
    'Cloudflare': '1.1.1.1',
    'Cloudflare-2': '1.0.0.1',
    'Quad9': '9.9.9.9',
    'OpenDNS': '208.67.222.222',
    'China-Ali': '223.5.5.5',
    'China-Tencent': '119.29.29.29',
    'Japan': '210.146.64.2',
    'Singapore': '165.21.83.88',
}

# é…ç½®å‚æ•°
class Config:
    DNS_TIMEOUT = 5  # DNS æŸ¥è¯¢è¶…æ—¶ï¼ˆç§’ï¼‰
    DNS_LIFETIME = 3  # DNS æŸ¥è¯¢ç”Ÿå‘½å‘¨æœŸï¼ˆç§’ï¼‰
    TCP_TIMEOUT = 5  # TCP è¿æ¥è¶…æ—¶ï¼ˆç§’ï¼‰
    SSL_TIMEOUT = 5  # SSL æ¡æ‰‹è¶…æ—¶ï¼ˆç§’ï¼‰
    MAX_WORKERS = 15  # æœ€å¤§å¹¶å‘æ•°
    MAX_IPS_PER_DOMAIN = 3  # æ¯ä¸ªåŸŸåä¿ç•™çš„ IP æ•°é‡
    RETRY_TIMES = 2  # é‡è¯•æ¬¡æ•°
    PORT = 443  # æµ‹è¯•ç«¯å£

# ==================== æ•°æ®ç»“æ„ ====================

@dataclass
class IPInfo:
    ip: str
    delay: float
    dns_sources: Set[str]
    ssl_verified: bool = False

# ==================== DNS æŸ¥è¯¢ ====================

def query_dns_server(dns_server: str, domain: str, dns_name: str) -> Tuple[str, List[str]]:
    """
    ä»æŒ‡å®š DNS æœåŠ¡å™¨æŸ¥è¯¢åŸŸå
    
    è¿”å›: (DNSåç§°, IPåˆ—è¡¨)
    """
    try:
        resolver = dns.resolver.Resolver()
        resolver.nameservers = [dns_server]
        resolver.timeout = Config.DNS_TIMEOUT
        resolver.lifetime = Config.DNS_LIFETIME
        
        answers = resolver.resolve(domain, 'A')
        ips = [str(rdata) for rdata in answers]
        
        if ips:
            logger.debug(f"  âœ“ {dns_name}({dns_server}): {len(ips)} IPs")
        
        return dns_name, ips
        
    except dns.resolver.NXDOMAIN:
        logger.debug(f"  âœ— {dns_name}: åŸŸåä¸å­˜åœ¨")
    except dns.resolver.Timeout:
        logger.debug(f"  âœ— {dns_name}: æŸ¥è¯¢è¶…æ—¶")
    except dns.resolver.NoAnswer:
        logger.debug(f"  âœ— {dns_name}: æ— åº”ç­”")
    except Exception as e:
        logger.debug(f"  âœ— {dns_name}: {type(e).__name__}")
    
    return dns_name, []

def get_ips_from_multiple_dns_servers(domain: str) -> Dict[str, IPInfo]:
    """
    ä»å¤šä¸ªå…¨çƒ DNS æœåŠ¡å™¨æŸ¥è¯¢è·å– IP
    
    è¿”å›: {ip: IPInfo}
    """
    logger.info(f"\n{'='*80}")
    logger.info(f"æ­£åœ¨æŸ¥è¯¢åŸŸå: {domain}")
    logger.info(f"{'='*80}")
    
    ip_dict = {}
    
    with ThreadPoolExecutor(max_workers=Config.MAX_WORKERS) as executor:
        futures = {
            executor.submit(query_dns_server, dns_ip, domain, name): name
            for name, dns_ip in DNS_SERVERS.items()
        }
        
        for future in as_completed(futures):
            dns_name = futures[future]
            try:
                name, ips = future.result()
                for ip in ips:
                    if ip not in ip_dict:
                        ip_dict[ip] = IPInfo(
                            ip=ip,
                            delay=float('inf'),
                            dns_sources=set()
                        )
                    ip_dict[ip].dns_sources.add(name)
                    
            except Exception as e:
                logger.error(f"  å¤„ç† {dns_name} ç»“æœæ—¶å‡ºé”™: {e}")
    
    logger.info(f"âœ“ ä» DNS è·å–åˆ° {len(ip_dict)} ä¸ªä¸åŒçš„ IP")
    
    return ip_dict

# ==================== è¿æ¥æµ‹è¯• ====================

def test_tcp_connection_with_ssl(
    ip: str, 
    domain: str, 
    port: int = 443, 
    timeout: int = 5
) -> Tuple[bool, float, bool]:
    """
    æµ‹è¯• TCP è¿æ¥å’Œ SSL æ¡æ‰‹
    
    è¿”å›: (è¿æ¥æˆåŠŸ, å»¶è¿Ÿms, SSLéªŒè¯æˆåŠŸ)
    """
    sock = None
    ssock = None
    
    try:
        # 1. TCP è¿æ¥æµ‹è¯•
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(timeout)
        
        start_time = time.time()
        sock.connect((ip, port))
        tcp_delay = (time.time() - start_time) * 1000
        
        # 2. SSL æ¡æ‰‹æµ‹è¯•
        ssl_verified = False
        try:
            context = ssl.create_default_context()
            context.check_hostname = False
            context.verify_mode = ssl.CERT_NONE
            
            ssock = context.wrap_socket(sock, server_hostname=domain)
            ssl_delay = (time.time() - start_time) * 1000
            ssl_verified = True
            
            logger.debug(f"    âœ“ {ip}: TCP={tcp_delay:.0f}ms, SSL={ssl_delay:.0f}ms")
            
            return True, ssl_delay, True
            
        except ssl.SSLError as e:
            logger.debug(f"    âš  {ip}: TCPæˆåŠŸ({tcp_delay:.0f}ms) ä½†SSLå¤±è´¥ - {e}")
            # TCP æˆåŠŸä½† SSL å¤±è´¥ï¼Œä»ç„¶è¿”å›è¿™ä¸ªç»“æœï¼ˆå¯èƒ½æ˜¯ä»£ç†æˆ– CDNï¼‰
            return True, tcp_delay, False
            
        except Exception as e:
            logger.debug(f"    âš  {ip}: SSLå¼‚å¸¸ - {type(e).__name__}")
            return True, tcp_delay, False
    
    except socket.timeout:
        logger.debug(f"    âœ— {ip}: è¿æ¥è¶…æ—¶")
        return False, timeout * 1000, False
        
    except ConnectionRefusedError:
        logger.debug(f"    âœ— {ip}: è¿æ¥è¢«æ‹’ç»")
        return False, timeout * 1000, False
        
    except OSError as e:
        logger.debug(f"    âœ— {ip}: {e}")
        return False, timeout * 1000, False
        
    except Exception as e:
        logger.debug(f"    âœ— {ip}: {type(e).__name__} - {e}")
        return False, timeout * 1000, False
        
    finally:
        # ç¡®ä¿èµ„æºè¢«é‡Šæ”¾
        if ssock:
            try:
                ssock.close()
            except:
                pass
        if sock:
            try:
                sock.close()
            except:
                pass

def test_ips(
    ip_dict: Dict[str, IPInfo], 
    domain: str, 
    port: int = 443, 
    timeout: int = 5
) -> List[IPInfo]:
    """
    å¹¶å‘æµ‹è¯•å¤šä¸ª IP çš„è¿é€šæ€§
    
    è¿”å›: æŒ‰å»¶è¿Ÿæ’åºçš„å¯ç”¨ IP åˆ—è¡¨
    """
    logger.info(f"\nå¼€å§‹æµ‹è¯• {len(ip_dict)} ä¸ª IP çš„è¿é€šæ€§...")
    
    reachable_ips = []
    failed_count = 0
    
    with ThreadPoolExecutor(max_workers=Config.MAX_WORKERS) as executor:
        futures = {
            executor.submit(test_tcp_connection_with_ssl, ip_info.ip, domain, port, timeout): ip_info
            for ip_info in ip_dict.values()
        }
        
        for future in as_completed(futures):
            ip_info = futures[future]
            try:
                success, delay, ssl_verified = future.result()
                
                if success:
                    ip_info.delay = delay
                    ip_info.ssl_verified = ssl_verified
                    reachable_ips.append(ip_info)
                    
                    ssl_status = "âœ“SSL" if ssl_verified else "âš NoSSL"
                    sources = ', '.join(sorted(list(ip_info.dns_sources)[:3]))
                    logger.info(f"  âœ“ {ip_info.ip:15s} | {delay:6.0f}ms | {ssl_status} | [{sources}]")
                else:
                    failed_count += 1
                    
            except Exception as e:
                logger.error(f"  âœ— {ip_info.ip}: æµ‹è¯•å¼‚å¸¸ - {e}")
                failed_count += 1
    
    # æŒ‰å»¶è¿Ÿæ’åºï¼Œä¼˜å…ˆé€‰æ‹© SSL éªŒè¯æˆåŠŸçš„
    reachable_ips.sort(key=lambda x: (not x.ssl_verified, x.delay))
    
    logger.info(f"\næµ‹è¯•ç»“æœ: âœ“ {len(reachable_ips)} ä¸ªå¯ç”¨, âœ— {failed_count} ä¸ªå¤±è´¥")
    
    return reachable_ips

# ==================== åŸŸåå¤„ç† ====================

def process_domains(
    domains: List[str], 
    max_ips_per_domain: int = 3, 
    output_file: str = "hosts.txt"
) -> None:
    """å¤„ç†å¤šä¸ªåŸŸåå¹¶ç”Ÿæˆ hosts æ–‡ä»¶"""
    
    logger.info(f"\n{'#'*80}")
    logger.info(f"# å¼€å§‹å¤„ç† {len(domains)} ä¸ªåŸŸå")
    logger.info(f"{'#'*80}\n")
    
    all_hosts = []
    stats = {'success': 0, 'failed': 0, 'no_ip': 0}
    
    for idx, domain in enumerate(domains, 1):
        logger.info(f"\n[{idx}/{len(domains)}] å¤„ç†åŸŸå: {domain}")
        
        try:
            # 1. DNS æŸ¥è¯¢
            ip_dict = get_ips_from_multiple_dns_servers(domain)
            
            if not ip_dict:
                logger.warning(f"âœ— æœªè·å–åˆ°ä»»ä½• IP")
                stats['no_ip'] += 1
                continue
            
            # 2. è¿é€šæ€§æµ‹è¯•
            reachable_ips = test_ips(ip_dict, domain, Config.PORT, Config.TCP_TIMEOUT)
            
            if not reachable_ips:
                logger.warning(f"âœ— æ‰€æœ‰ IP å‡ä¸å¯è¾¾")
                stats['failed'] += 1
                continue
            
            # 3. é€‰æ‹©æœ€ä¼˜ IP
            top_ips = reachable_ips[:max_ips_per_domain]
            logger.info(f"\nâœ“ ä¸º {domain} é€‰æ‹©äº† {len(top_ips)} ä¸ªæœ€ä¼˜ IP:")
            
            for rank, ip_info in enumerate(top_ips, 1):
                ssl_mark = "ğŸ”’" if ip_info.ssl_verified else "âš ï¸"
                sources_str = ', '.join(sorted(list(ip_info.dns_sources)[:2]))
                logger.info(f"  #{rank}. {ip_info.ip:15s} | {ip_info.delay:6.0f}ms | {ssl_mark} | [{sources_str}]")
                all_hosts.append((ip_info.ip, domain))
            
            stats['success'] += 1
            
        except Exception as e:
            logger.error(f"âœ— å¤„ç† {domain} æ—¶å‡ºé”™: {e}", exc_info=True)
            stats['failed'] += 1
    
    # 4. ç”Ÿæˆè¾“å‡º
    logger.info(f"\n{'#'*80}")
    logger.info(f"# å¤„ç†å®Œæˆ")
    logger.info(f"# æˆåŠŸ: {stats['success']}, å¤±è´¥: {stats['failed']}, æ— IP: {stats['no_ip']}")
    logger.info(f"# å…±è·å¾— {len(all_hosts)} æ¡ hosts è®°å½•")
    logger.info(f"{'#'*80}\n")
    
    if all_hosts:
        host_infos = generate_hosts_content(all_hosts)
        write_hosts_file(host_infos, output_file)
        write_hosts_file(host_infos, "hosts.txt")
        
        # æ›´æ–° READMEï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        try:
            write_hosts_to_readme(host_infos)
        except Exception as e:
            logger.warning(f"æ›´æ–° README å¤±è´¥: {e}")
    else:
        logger.error("æ²¡æœ‰ç”Ÿæˆä»»ä½• hosts è®°å½•ï¼")

# ==================== æ–‡ä»¶è¾“å‡º ====================

def generate_hosts_content(hosts: List[Tuple[str, str]]) -> str:
    """ç”Ÿæˆ hosts æ–‡ä»¶å†…å®¹"""
    lines = [
        "# GitHub Hosts - Auto Generated",
        f"# Generated at: {time.strftime('%Y-%m-%d %H:%M:%S')}",
        f"# Total entries: {len(hosts)}",
        f"# DNS Servers: {len(DNS_SERVERS)}",
        "",
    ]
    
    # æŒ‰åŸŸååˆ†ç»„
    domain_groups = {}
    for ip, domain in hosts:
        if domain not in domain_groups:
            domain_groups[domain] = []
        domain_groups[domain].append(ip)
    
    # ç”Ÿæˆå†…å®¹
    for domain in sorted(domain_groups.keys()):
        lines.append(f"# {domain}")
        for ip in domain_groups[domain]:
            lines.append(f"{ip}\t{domain}")
        lines.append("")
    
    lines.append("# Hosts END")
    
    return "\n".join(lines)

def write_hosts_file(content: str, output_file: str) -> bool:
    """å†™å…¥ hosts æ–‡ä»¶"""
    try:
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        logger.info(f"âœ“ æˆåŠŸå†™å…¥åˆ°: {output_path.absolute()}")
        
        # æ˜¾ç¤ºé¢„è§ˆ
        lines = content.split('\n')
        if len(lines) > 20:
            preview = '\n'.join(lines[:10] + ['...', f'(çœç•¥ {len(lines)-20} è¡Œ)', '...'] + lines[-10:])
        else:
            preview = content
            
        logger.info(f"\næ–‡ä»¶å†…å®¹é¢„è§ˆ:\n{'-'*80}\n{preview}\n{'-'*80}\n")
        
        return True
        
    except Exception as e:
        logger.error(f"âœ— å†™å…¥æ–‡ä»¶å¤±è´¥: {e}")
        return False

def write_hosts_to_readme(content: str) -> None:
    """æ›´æ–° README.md"""
    readme_path = Path("README.md")
    
    if not readme_path.exists():
        logger.warning("README.md ä¸å­˜åœ¨ï¼Œè·³è¿‡æ›´æ–°")
        return
    
    try:
        with open(readme_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        # æŸ¥æ‰¾æ’å…¥ä½ç½®
        insert_index = -1
        for i, line in enumerate(lines):
            if "### ğŸš€ æ›´æ„‰å¿«çš„ clone ğŸš€" in line:
                insert_index = i + 2
                break
        
        if insert_index == -1:
            logger.warning("æœªåœ¨ README.md ä¸­æ‰¾åˆ°æ’å…¥æ ‡è®°")
            return
        
        # æ„å»ºæ–°å†…å®¹
        new_content = [
            lines[insert_index],  # ä¿ç•™åŸæœ‰æ ‡é¢˜
            "\n",
            "```txt\n",
            content,
            "\n```\n",
            "\n",
            "å¦‚æœæœ¬åœ°ç¬¬ä¸€ä¸ªå¤±æ•ˆï¼Œå»ºè®®æ³¨é‡Šæµ‹è¯•ä¸‹ä¸€ä¸ª\n",
            "\n",
            "å¸Œæœ›ç»™ä½ å¸¦æ¥å‹å¥½çš„ä½“éªŒ~\n",
            "\n",
            "Thanks [GitHub520](https://github.com/521xueweihan/GitHub520)\n",
        ]
        
        # é‡å»ºæ–‡ä»¶
        final_lines = lines[:insert_index] + new_content
        
        with open(readme_path, 'w', encoding='utf-8') as f:
            f.writelines(final_lines)
        
        logger.info("âœ“ æˆåŠŸæ›´æ–° README.md")
        
    except Exception as e:
        logger.error(f"âœ— æ›´æ–° README.md å¤±è´¥: {e}")

# ==================== å·¥å…·å‡½æ•° ====================

def load_domains_from_file(filename: str) -> List[str]:
    """ä»æ–‡ä»¶è¯»å–åŸŸååˆ—è¡¨"""
    try:
        file_path = Path(filename)
        
        if not file_path.exists():
            logger.error(f"âœ— æ–‡ä»¶ä¸å­˜åœ¨: {file_path.absolute()}")
            return []
        
        with open(file_path, 'r', encoding='utf-8') as f:
            domains = []
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                
                # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Š
                if not line or line.startswith('#'):
                    continue
                
                # ç®€å•éªŒè¯åŸŸåæ ¼å¼
                if '.' in line and ' ' not in line:
                    domains.append(line)
                else:
                    logger.warning(f"ç¬¬ {line_num} è¡Œæ ¼å¼å¯èƒ½æœ‰è¯¯: {line}")
            
            logger.info(f"âœ“ ä» {filename} è¯»å–åˆ° {len(domains)} ä¸ªåŸŸå")
            return domains
            
    except Exception as e:
        logger.error(f"âœ— è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return []

# ==================== ä¸»ç¨‹åº ====================

def query_ips():
    """ä¸»å‡½æ•°"""
    logger.info("="*80)
    logger.info("GitHub Hosts è‡ªåŠ¨æŸ¥è¯¢å·¥å…·")
    logger.info("="*80)
    
    # è¯»å–åŸŸååˆ—è¡¨
    conf_path = Path("conf/domains.txt")
    domains = load_domains_from_file(conf_path)
    
    if not domains:
        logger.error("æ²¡æœ‰æ‰¾åˆ°éœ€è¦æŸ¥è¯¢çš„åŸŸåï¼Œç¨‹åºé€€å‡º")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    save_dir = Path("data")
    save_dir.mkdir(exist_ok=True)
    
    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    timestamp = dt.datetime.now().strftime("%Y_%m_%d_%H%M%S")
    save_path = save_dir / f"{timestamp}.txt"
    
    # å¤„ç†åŸŸå
    start_time = time.time()
    process_domains(
        domains, 
        max_ips_per_domain=Config.MAX_IPS_PER_DOMAIN, 
        output_file=str(save_path)
    )
    
    elapsed = time.time() - start_time
    logger.info(f"\n{'='*80}")
    logger.info(f"âœ“ ä»»åŠ¡å®Œæˆï¼æ€»è€—æ—¶: {elapsed:.1f} ç§’")
    logger.info(f"{'='*80}")

if __name__ == "__main__":
    try:
        query_ips()
    except KeyboardInterrupt:
        logger.warning("\nç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        logger.error(f"\nç¨‹åºå¼‚å¸¸é€€å‡º: {e}", exc_info=True)